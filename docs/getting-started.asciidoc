[[getting-started]]
== Getting Started

[float]
=== The demo distribution
The quickest way to get started with Kibi is to download the Kibi demo
distribution from http://siren.solutions/kibi ; the page contains also
introductory screencast which we recommend to watch.

The Kibi demo distribution includes a ready to use Elasticsearch cluster in
the `elasticsearch` directory; the cluster contains five indices:

[horizontal]
`company`:: a collection of companies
`article`:: a collection of articles about companies
`investment`:: a collection of investments in companies
`investor`:: a collection of investors
`.kibi`:: Kibi configuration

The indices have been populated through https://www.elastic.co/products/logstash[Logstash]
from the SQLite database in `kibi/crunchbase.db`; the Logstash configuration
used to populate the indices is described in the <<logstash>> chapter.

NOTE: The demo dataset has been built from a sample of articles gathered from
tech blogs in 2013 and from data about companies, investments and investors in
the CrunchBase 2013 Snapshot, which is copyright (C) 2013 AOL Inc.

The current CrunchBase dataset is available at http://data.crunchbase.com/.

[float]
=== Search
After starting Elasticsearch and Kibi, as described in the <<setup, Setup chapter>>,
start your web browser and navigate to {start-url} or for installation with Shield {start-url-shield}.

By default, Kibi displays the _Articles_ dashboard; <<dashboard, dashboards>>
can be configured to display multiple <<visualize, visualizations>> on the
documents stored in a specific index or returned by a <<save-search,saved search>> on an index.

Each dashboard is represented by a tab containing the dashboard title and
the number of documents available to visualizations.

image::images/getting-started/demo-overview.png["The articles dashboard",align="center"]

You can quickly search specific articles through the search input in the
navigation bar; for example, let's find all the articles written about
_wireless_ or _wifi_:

image::images/getting-started/demo-dashboard-search.png["The dashboard search bar",align="center"]

We can immediately see that there are 11693 articles about those topics and
all the visualizations are refreshed to aggregate data for this subset of
articles.

NOTE: besides simple text, queries in the search bar can be written using the
Lucene https://lucene.apache.org/core/2_9_4/queryparsersyntax.html[query
syntax], or {elastic-ref}query-dsl.html[Elasticsearch Query DSL].

Video tutorials are also available:

* https://www.elastic.co/blog/kibana-4-video-tutorials-part-1[High-level Kibana 4 introduction, pie charts]
* https://www.elastic.co/blog/kibana-4-video-tutorials-part-2[Data discovery, bar charts, and line charts]
* https://www.elastic.co/blog/kibana-4-video-tutorials-part-3[Tile maps]
* https://www.elastic.co/blog/kibana-4-video-tutorials-part-4[Embedding Kibana 4 visualizations]

[float]
=== Filters
Visualizations can be used to create filters; for example, you can see all the
articles about _wireless_ or _wifi_ published by TechCrunch by clicking on
the _TechCrunch_ slice inside the _Articles by Source_ <<pie-chart, pie chart>>
visualization:

image::images/getting-started/demo-pie-slice.png["Clicking on a pie slice",align="center"]

image::images/getting-started/demo-pie-filter.png["The dashboard with the filter on the slice applied",align="center"]

NOTE: To disable a filter, just move the mouse over it and click on the
checkbox icon; you can disable all the filters applied to the dashboard by
clicking on _Actions_ and then _Disable_; for more information about filtering,
please read the <<visualize-filters, filters>> chapter.

[[tutorial-load-dataset]]
=== Before You Start: Loading Sample Data

The tutorials in this section rely on the following data sets:

* The complete works of William Shakespeare, suitably parsed into fields. Download this data set by clicking here:
  https://www.elastic.co/guide/en/kibana/3.0/snippets/shakespeare.json[shakespeare.json].
* A set of fictitious accounts with randomly generated data. Download this data set by clicking here:
  https://github.com/bly2k/files/blob/master/accounts.zip?raw=true[accounts.zip]
* A set of randomly generated log files. Download this data set by clicking here:
  https://download.elastic.co/demos/kibana/gettingstarted/logs.jsonl.gz[logs.jsonl.gz]

Two of the data sets are compressed. Use the following commands to extract the files:

[source,shell]
unzip accounts.zip
gunzip logs.jsonl.gz

The Shakespeare data set is organized in the following schema:

[source,json]
{
    "line_id": INT,
    "play_name": "String",
    "speech_number": INT,
    "line_number": "String",
    "speaker": "String",
    "text_entry": "String",
}

The accounts data set is organized in the following schema:

[source,json]
{
    "account_number": INT,
    "balance": INT,
    "firstname": "String",
    "lastname": "String",
    "age": INT,
    "gender": "M or F",
    "address": "String",
    "employer": "String",
    "email": "String",
    "city": "String",
    "state": "String"
}

The schema for the logs data set has dozens of different fields, but the notable ones used in this tutorial are:

[source,json]
{
    "memory": INT,
    "geo.coordinates": "geo_point"
    "@timestamp": "date"
}

Before we load the Shakespeare data set, we need to set up a {ref}/mapping.html[_mapping_] for the fields. Mapping
divides the documents in the index into logical groups and specifies a field's characteristics, such as the field's
searchability or whether or not it's _tokenized_, or broken up into separate words.

Use the following command to set up a mapping for the Shakespeare data set:

[source,shell]
curl -XPUT http://localhost:9200/shakespeare -d '
{
 "mappings" : {
  "_default_" : {
   "properties" : {
    "speaker" : {"type": "string", "index" : "not_analyzed" },
    "play_name" : {"type": "string", "index" : "not_analyzed" },
    "line_id" : { "type" : "integer" },
    "speech_number" : { "type" : "integer" }
   }
  }
 }
}
';

This mapping specifies the following qualities for the data set:

* The _speaker_ field is a string that isn't analyzed. The string in this field is treated as a single unit, even if
there are multiple words in the field.
* The same applies to the _play_name_ field.
* The _line_id_ and _speech_number_ fields are integers.

The logs data set requires a mapping to label the latitude/longitude pairs in the logs as geographic locations by
applying the `geo_point` type to those fields.

Use the following commands to establish `geo_point` mapping for the logs:

[source,shell]
curl -XPUT http://localhost:9200/logstash-2015.05.18 -d '
{
  "mappings": {
    "log": {
      "properties": {
        "geo": {
          "properties": {
            "coordinates": {
              "type": "geo_point"
            }
          }
        }
      }
    }
  }
}
';

[source,shell]
curl -XPUT http://localhost:9200/logstash-2015.05.19 -d '
{
  "mappings": {
    "log": {
      "properties": {
        "geo": {
          "properties": {
            "coordinates": {
              "type": "geo_point"
            }
          }
        }
      }
    }
  }
}
';

[source,shell]
curl -XPUT http://localhost:9200/logstash-2015.05.20 -d '
{
  "mappings": {
    "log": {
      "properties": {
        "geo": {
          "properties": {
            "coordinates": {
              "type": "geo_point"
            }
          }
        }
      }
    }
  }
}
';

The accounts data set doesn't require any mappings, so at this point we're ready to use the Elasticsearch
{ref}/docs-bulk.html[`bulk`] API to load the data sets with the following commands:

[source,shell]
curl -XPOST 'localhost:9200/bank/account/_bulk?pretty' --data-binary @accounts.json
curl -XPOST 'localhost:9200/shakespeare/_bulk?pretty' --data-binary @shakespeare.json
curl -XPOST 'localhost:9200/_bulk?pretty' --data-binary @logs.jsonl

These commands may take some time to execute, depending on the computing resources available.

Verify successful loading with the following command:

[source,shell]
curl 'localhost:9200/_cat/indices?v'

You should see output similar to the following:

[source,shell]
health status index               pri rep docs.count docs.deleted store.size pri.store.size
yellow open   bank                  5   1       1000            0    418.2kb        418.2kb
yellow open   shakespeare           5   1     111396            0     17.6mb         17.6mb
yellow open   logstash-2015.05.18   5   1       4631            0     15.6mb         15.6mb
yellow open   logstash-2015.05.19   5   1       4624            0     15.7mb         15.7mb
yellow open   logstash-2015.05.20   5   1       4750            0     16.4mb         16.4mb

[[tutorial-define-index]]
=== Defining Your Index Patterns

Each set of data loaded to Elasticsearch has an <<settings-create-pattern,index pattern>>. In the previous section, the
Shakespeare data set has an index named `shakespeare`, and the accounts
data set has an index named `bank`. An _index pattern_ is a string with optional wildcards that can match multiple
indices. For example, in the common logging use case, a typical index name contains the date in MM-DD-YYYY
format, and an index pattern for May would look something like `logstash-2015.05*`.

For this tutorial, any pattern that matches the name of an index we've loaded will work. Open a browser and
navigate to `localhost:5601`. Click the *Settings* tab, then the *Indices* tab. Click *Add New* to define a new index
pattern. Two of the sample data sets, the Shakespeare plays and the financial accounts, don't contain time-series data.
Make sure the *Index contains time-based events* box is unchecked when you create index patterns for these data sets.
Specify `shakes*`  as the index pattern for the Shakespeare data set and click *Create* to define the index pattern, then
define a second index pattern named `ba*`.

The Logstash data set does contain time-series data, so after clicking *Add New* to define the index for this data
set, make sure the *Index contains time-based events* box is checked and select the `@timestamp` field from the
*Time-field name* drop-down.

NOTE: When you define an index pattern, indices that match that pattern must exist in Elasticsearch. Those indices must
contain data.

[float]
=== Relational filters
The <<relational-filter, Relational Filter>> visualization allows to
create cross-dashboard filters; for example, by looking at the _Companies_
button in the dashboard, you can see that there are 96 companies mentioned in
the TechCrunch articles about _wireless_ or _wifi_.

image::images/getting-started/demo-companies-relational-filter.png["A relational filter button",align="center"]

By clicking on the button, you can switch to the _Companies_ dashboard and
visualize the data about these 96 companies:

image::images/getting-started/demo-companies-dashboard-overview.png["Relational filter from Articles to Companies",align="center"]

The relational filter created by clicking on the button is displayed in the
filter bar, and can be disabled or deleted just like any other filter; moving
the mouse over the filter will display the list of joined indices and their
filters:

image::images/getting-started/relational-filter-explanation.png["Relational filter in the filter bar",align="center"]

Relational filter can be accumulated; for example, if you click on the
`Investment rounds -->` button, you will see data about the 24 investment
rounds related to a subset of 96 companies mentioned in the TechCrunch articles
about _wireless_ or _wifi_.

Click on the _Companies_ tab to go back to the Companies dashboard.

To understand how to define a relational filter, click the pencil icon
inside the _Relational widget_ visualization heading; this will open the
configuration editor:

image::images/getting-started/relational-filter-config.png["Relational filter configuration",align="center", width="300"]

As you can see, it is possible to set two different values for label displayed
on the button and for the label displayed in the filter; it is also possible
to use a single configuration for all the dashboards, as the visualization will
display only buttons relevant to the currently displayed dashboard.

Click on the _Dashboard_ tab to go back to the Companies dashboard.

NOTE: for more informations about relational filters, please read the
<<relational-filter>> chapter.

[float]
=== Query based aggregations

It is possible to get additional information about companies by using the
results of queries on SQL databases (or any of the datasources supported by
Kibi) as aggregations on Elasticsearch documents.

For example, in the _Query on Companies_ visualization you can see that 40 of
the 96 companies have competitors and 11 of them are in the top 500 companies
by number of employees:

image::images/getting-started/demo-query-companies.png["SQL based aggregations",align="center"]

`Companies "With competitors"` and `Top 500 companies (HR count)` are <<datasource-queries, queries>>
on the SQLite database; the records returned by the queries are used to filter
Elasticsearch documents, which can be then aggregated in a metric.

To better understand this feature, let's have a look at the
`Top 500 companies (HR count)` query; to see the query, click on the _Settings_
tab, then on _Queries_ and on the _Open_ button:

image::images/getting-started/settings-queries.png["The query editor",align="center"]

The query returns the `id`, `label` and `number_of_employees` columns
from the `company` table for the top 500 companies by number of employees:

[source,sql]
select id, label, number_of_employees
from company
where number_of_employees>0
order by number_of_employees desc
limit 500

Click on the Dashboard tab, then click on the pencil icon in the heading of
the _Query on Companies_ visualization to customize its configuration:

image::images/getting-started/dashboard-edit-query-vis.png["Editing the Query on Companies visualization",align="center"]

The _metrics_ section defines the aggregations on Elasticsearch documents,
displayed as columns in the table; the _buckets_ section defines the groups
of Elasticsearch documents aggregated by metrics, displayed as row headers
in the table.

By expanding the _Split Rows_ section inside _buckets_ you can see how the
queries are used to define groups of Elasticsearch documents:

image::images/getting-started/dashboard-edit-query-vis-agg.png["Query on Companies configuration",align="center"]

Scroll down to see the configuration of the fourth filter:

image::images/getting-started/query-vis-filter-agg.png["Configuration of an external query terms filter",align="center"]

The filter is configured to execute the query `Top 500 companies (HR count)`
on the SQLite database and return the group of Elasticsearch documents from
the current search whose `id` is equal to one of the id's in the query
results; the documents are then processed by the _Count_ metric.

Let's add a new aggregation to show the average number of employees; click
on _Add metrics_ inside the _metrics_ section, then select `Metric` as the
metric type; select `Average` as the aggregation and `number_of_employees`
as the field, the click on the green button to apply changes.

Save the visualization by clicking on the _Save_ button, confirm that you
want to overwrite the existing visualization, then click on the _Dashboard_
tab to see the updated visualization in the _Companies_ dashboard:

image::images/getting-started/query-vis-avg.png["Average aggregation",align="center"]

Click *Add sub-buckets* at the bottom, then select *Split Slices*. Choose the *Terms* aggregation and the *age* field from
the drop-downs.
Click the green *Apply changes* button image:images/apply-changes-button.png[] to add an external ring with the new
results.

NOTE: read the <<aggregation-builder>> chapter for an in-depth explanation of
aggregations.

Besides defining groups to aggregate, queries can be used as filters; click
on the _Dashboard_ tab, then click on the _Top-500-companies-(HR-count)_
row to see only the 11 companies mentioned in the articles which are also in
the top 500 by number of employees:

image::images/getting-started/query-vis-filterbar.png["Filter dashboard using a SQL query",align="center"]

[float]
=== Datasource entity selection

It is possible to select a company entity (record) in the SQLite database (
and entities in <<external-datasources, external datasources>> in general) by
clicking on its label in the _Companies Table_.

The selected entity can be used as a parameter in <<datasource-queries, queries>>;
for example, click on `Baidu` in _Companies Table_:

image::images/getting-started/entity-selection.png["Entity selection",align="center", width="800"]

Selecting an entity enables additional queries on external datasources; for
example, in the _Query on Companies_ visualization you can see that, amongst
the top 500 companies by number of employees mentioned in articles about
`wireless` or `wifi`, `Baidu` has one competitor and there are five companies
in the same domain.
All widgets affected by the selected entity are marked by a purple header.

For the Y-axis metrics aggregation, select *Unique Count*, with *speaker* as the field. For Shakespeare plays, it might
be useful to know which plays have the lowest number of distinct speaking parts, if your theater company is short on
actors. For the X-Axis buckets, select the *Terms* aggregation with the *play_name* field. For the *Order*, select
*Ascending*, leaving the *Size* at 5.

Leave the other elements at their default values and click the green *Apply changes* button image:images/apply-changes-button.png[]. Your chart should now look
like this:

Selecting an entity also enables the display of additional data in the
_Company Info_ visualization; by clicking on the _(show)_ links you can
toggle the list of companies in the same domain and competitors; the data in
the tables is fetched from queries on the SQLite database, using the selected
company ID as a parameter. The queries are rendered using
<<kibi-query-viewer, customizable templates>>, which will be introduced
later.

The selected entity appears as a purple box on the right of the filter bar;
to deselect an entity, click on the bin icon displayed when moving the mouse
over the purple box.

NOTE: for additional documentation about entity selection, please read the
<<entity-selection>> section in the <<external-datasources>> chapter.

[float]
=== Enhanced search results

The <<enhanced-search-results>> visualization displays the current set of
Elasticsearch documents as a table; for example, _Companies Table_ is
configured to display the following fields:

- Time (foundation date)
- label (the company name)
- description
- category_code
- founded_year
- countrycode
- Why Relevant? (a <<relational-column, relational column>>)

image::images/getting-started/companies-table.png["Companies table",align="center"]

By clicking on the pencil icon, you can choose which fields to display and
customize the order of the columns; if the index is time based, the `Time`
column will be always displayed.

For example, expand the first row by clicking on the right arrow, then scroll
down to the `homepage_url` field and click on the Toggle column icon:

image::images/getting-started/companies-table-preview.png["Companies table preview",align="center"]

Click on the arrows to move the column to the desired position:

image::images/getting-started/companies-table-colmove.png["Column positioning",align="center"]

[float]
==== Click handlers

You can define click handlers on cells to perform several actions; let's add a
click handler to open the company homepage when clicking on the cell displaying
the URL.

The table is pre-configured with a click handler on `label` that is used to
select an entity in the SQLite database.

To add a new click handler, scroll down _view options_ and click on
_Add click handler_; select `homepage_url` in the _Column_ dropdown, then
`Follow the URL` in the _On click I want to_ dropdown. Select `homepage_url`
as the _URL field_, then click on the green button to apply changes.

You can test the click handler immediately by clicking on a cell displaying
an homepage URL in the preview displayed on the right:

image::images/getting-started/click-handler-url.png["URL click handler",align="center"]

[float]
==== Relational column

The relational column can be enabled to display if an Elasticsearch document
is matched by a query on the SQLite database.

For example, in the _Companies Table_, you can see that `Verizon` is in the
top 50 companies by number of employees by looking at the Why Relevant? column
because the `label-not-analyzed` field of the corresponding Elasticsearch
document is matched by the `label` column in at least one of the records
returned by the `Top 50 companies (HR count)` query.

Queries set in the relational column configuration can also take the selected
entity as a parameter, so you can see that `Yahoo!` is both a competitor and
a company in the same domain as `Baidu`:

image::images/getting-started/relational-column-example.png["Relational column example",align="center"]

image::images/getting-started/relational-column-config.png["Relational column configuration",align="center"]

[float]
==== Saving the visualization

Click on the save button in the top right to save the visualization, then
click on the _Dashboard_ tab to go back to the Companies dashboard.

NOTE: for additional documentation about this visualization, please read the
<<enhanced-search-results>> chapter.

[float]
=== Query templates

_Company Info_, which is an instance of a Kibi query viewer visualization,
displays the results of three SQL queries by rendering their results through
templates; the queries take the selected entity ID as an input, thus the
associated templates will be displayed only when an entity is selected.

image::images/getting-started/templated-query-viewer.png["Kibi query viewer example",align="center"]

The association between query and templates can be set in the visualization
configuration:

image::images/getting-started/templated-query-viewer-config.png["Kibi query viewer configuration",align="center"]

Query templates can be managed by clicking on the _Settings_ tab, then on the
_Query templates_ tab.

NOTE: you can find the documentation about templates in the
<<external-datasources>> chapter; the visualization is documented in the
<<kibi-query-viewer>> chapter.
